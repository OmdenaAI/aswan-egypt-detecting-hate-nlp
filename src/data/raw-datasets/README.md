# Raw Data (English)

Given that the upload of large dataset is against GitHub best practices, we shall merely upload our *cleaned* datasets in this repository, and leave the *raw* datasets in their original locations.

The table below lists the datasets chosen for our project, their location, and the people to which each dataset is assigned.

## Chosen Datasets

| Dataset | Dataset Name | Link | Assigned to |
|-|-|-|-|
|1| HateXplain| [https://github.com/hate-alert/HateXplain](https://github.com/hate-alert/HateXplain) |         |
|2| Toxic Comment Classification Challenge | [https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge/data](https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge/data) |         |
|3| measuring-hate-speech | [https://huggingface.co/datasets/ucberkeley-dlab/measuring-hate-speech](https://huggingface.co/datasets/ucberkeley-dlab/measuring-hate-speech) | Ameya Chaudhari |
|4| 44 datasets | [https://paperswithcode.com/datasets?q=Hate+Speech&v=lst&o=match&mod=texts&lang=english](https://paperswithcode.com/datasets?q=Hate+Speech&v=lst&o=match&mod=texts&lang=english) | Repeats already used datasets. Do not use for English. See below for Arabic. |
|5| hate-speech-dataset | [https://github.com/Vicomtech/hate-speech-dataset](https://github.com/Vicomtech/hate-speech-dataset) | Numerous datasets, see "hate-speech-dataset" for details and assignments. |
|6|         |         |         |
|7|         |         |         |
|8| hate_speech_offensive | [https://huggingface.co/datasets/hate_speech_offensive](https://huggingface.co/datasets/hate_speech_offensive) | Ameya Chaudhari |
|9|         |         |         |
|10|        |         |         |
|11| Twitter Tweets Sentiment | [https://www.kaggle.com/datasets/yasserh/twitter-tweets-sentiment-dataset](https://www.kaggle.com/datasets/yasserh/twitter-tweets-sentiment-dataset) | Ameya Chaudhari |
|12|        |         |         |

Please note that every addition/modification of the chosen data pool will have to be discussed with the task leaders (@VishuKalier2003 and @CaterinaBi).

# hate-speech-datasets

This is the breakdown of the '44 Datasets' from the table above ([5]).

| Dataset | Dataset Name | Link | Assigned to |
|-|-|-|-|
|1|         |         |         |
|2|         |         |         |
|3|         |         |         |
|4|         |         |         |
|5|         |         |         |
|6|         |         |         |
|7|         |         |         |
|8|         |         |         |
|9|         |         |         |
|10|        |         |         |
|11|         |         |         |
|12|         |         |         |
|13|         |         |         |
|14|         |         |         |
|15|         |         |         |
|16|         |         |         |
|17|         |         |         |
|18|         |         |         |
|19|         |         |         |
|20|        |         |         |

# Raw Data (Multilingual Datasets containing Arabic)

Resources for those interested in working on Arabic.

| Dataset | Dataset Name | Link | Assigned to |
|-|-|-|-|
|1| AraCOVID19-MFH | [https://paperswithcode.com/dataset/aracovid19-mfh](https://paperswithcode.com/dataset/aracovid19-mfh) |         |
|2| CVSS | [https://paperswithcode.com/dataset/cvss](https://paperswithcode.com/dataset/cvss) |         |
|3| CoVoST | [https://paperswithcode.com/dataset/covost](https://paperswithcode.com/dataset/covost) |         |
|4| Universal Dependencies | [https://paperswithcode.com/dataset/universal-dependencies](https://paperswithcode.com/dataset/universal-dependencies) |         |
|5| MuST-C | [https://paperswithcode.com/dataset/must-c](https://paperswithcode.com/dataset/must-c) |         |
|6| OntoNotes 5.0 | [https://paperswithcode.com/dataset/ontonotes-5-0](https://paperswithcode.com/dataset/ontonotes-5-0) |         |
