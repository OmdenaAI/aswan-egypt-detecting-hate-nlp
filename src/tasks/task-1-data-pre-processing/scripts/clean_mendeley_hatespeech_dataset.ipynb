{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0a9f3ce",
   "metadata": {},
   "source": [
    " # <span style=\"font-family: TrebucImport all required moduleshet MS; font-weight:bold;font-size:1.5em;color:#00b3e5;\">  Preprocessing script"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6547ca7",
   "metadata": {},
   "source": [
    "## <span style=\"font-family: Trebuchet MS; font-weight:bold;font-size:0.7em;color:darkorange;\"> The raw data is available in the link https://data.mendeley.com/datasets/9sxpkmm8xn. Since it is more than 2GB data, no matter how you search it will not be available in this git repo. So before running this sript - download the zip, extract and have data_huang_devansh.csv available with you. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0304b6e8",
   "metadata": {},
   "source": [
    "<a id='Imports'></a>\n",
    "\n",
    "## <span style=\"font-family: Trebuchet MS; font-weight:bold;font-size:1.2em;color:#00b3e5;\">  Import all required modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "636cbf1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "520bdcce",
   "metadata": {},
   "source": [
    "## <span style=\"font-family: Trebuchet MS; font-weight:bold;font-size:1.2em;color:#00b3e5;\">  Common functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e2072ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_df_details(df):\n",
    "    print(\"\\n****** Start Dataframe Details ******\")\n",
    "    print(\"Dataframe Shape is \")\n",
    "    print(df.shape)\n",
    "    print(\"Dataframe Info is \")\n",
    "    print(df.info())\n",
    "    print(\"Dataframe random records \")\n",
    "    display(df.sample(5) if len(df) > 5 else df.sample(1))\n",
    "    print(\"****** End Dataframe Details ******\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6dfd89dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read file and convert it to Dataframe\n",
    "def file_to_df(fqfn, file_type='csv'):\n",
    "    df = 'None'\n",
    "    if (file_type == 'csv'):\n",
    "        df = pd.read_csv(fqfn, skipinitialspace = True)\n",
    "    else:\n",
    "        raise ValueError('Unsupported filetype ', file_type)\n",
    "    print_df_details(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41e04ddb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "****** Start Dataframe Details ******\n",
      "Dataframe Shape is \n",
      "(842335, 2)\n",
      "Dataframe Info is \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 842335 entries, 0 to 842334\n",
      "Data columns (total 2 columns):\n",
      " #   Column   Non-Null Count   Dtype \n",
      "---  ------   --------------   ----- \n",
      " 0   Content  842308 non-null  object\n",
      " 1   Label    842335 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 12.9+ MB\n",
      "None\n",
      "Dataframe random records \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Content</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>789983</th>\n",
       "      <td>@user Shut the fuck up you horrible cunt</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12634</th>\n",
       "      <td>BTW, there's this dipshit (his name is LILVOKA...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349149</th>\n",
       "      <td>== Clarifying .. ==  Hi there !  I just want...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411745</th>\n",
       "      <td>@sschinke @teh_maxh it sets a bad precedent.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>577154</th>\n",
       "      <td>I think we should further develop the pagan-or...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Content  Label\n",
       "789983           @user Shut the fuck up you horrible cunt      1\n",
       "12634   BTW, there's this dipshit (his name is LILVOKA...      1\n",
       "349149    == Clarifying .. ==  Hi there !  I just want...      0\n",
       "411745       @sschinke @teh_maxh it sets a bad precedent.      0\n",
       "577154  I think we should further develop the pagan-or...      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** End Dataframe Details ******\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = file_to_df('data_huang_devansh.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a02ac90",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d73fecea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e2e4c5d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "nltk_stop_words = stopwords.words('english')\n",
    "print(nltk_stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "83e58736",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "****** Start Dataframe Details ******\n",
      "Dataframe Shape is \n",
      "(560881, 2)\n",
      "Dataframe Info is \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 560881 entries, 0 to 839518\n",
      "Data columns (total 2 columns):\n",
      " #   Column   Non-Null Count   Dtype \n",
      "---  ------   --------------   ----- \n",
      " 0   Content  560879 non-null  object\n",
      " 1   Label    560881 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 12.8+ MB\n",
      "None\n",
      "Dataframe random records \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Content</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>411804</th>\n",
       "      <td>RT @freddydeknatel: \"credible reports that Ira...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564832</th>\n",
       "      <td>\"\\n\\n Corsi's \"\"apology\"\" for remarks on FR \\n...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>558163</th>\n",
       "      <td>\"\\n\\n Your sig... \\n\\nI'm curious as to how yo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510772</th>\n",
       "      <td>\"\\n\\n National Archives ExtravaSCANza \\nYou ar...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342462</th>\n",
       "      <td>::I think the notability comes from the notab...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Content  Label\n",
       "411804  RT @freddydeknatel: \"credible reports that Ira...      0\n",
       "564832  \"\\n\\n Corsi's \"\"apology\"\" for remarks on FR \\n...      0\n",
       "558163  \"\\n\\n Your sig... \\n\\nI'm curious as to how yo...      0\n",
       "510772  \"\\n\\n National Archives ExtravaSCANza \\nYou ar...      0\n",
       "342462   ::I think the notability comes from the notab...      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** End Dataframe Details ******\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.drop_duplicates(inplace=True)\n",
    "print_df_details(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dccd6ae1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(560879, 2)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dropna(inplace=True)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3eadb3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "wordnet_lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7152f595",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>208905</th>\n",
       "      <td>caught bothering something I long learned bother</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 content  label\n",
       "208905  caught bothering something I long learned bother      0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content=[]\n",
    "label=[]\n",
    "for row in data.values:\n",
    "    new_sentence = \"\"\n",
    "    old_sentence = row[0].split()\n",
    "    for word in old_sentence:\n",
    "        if word.find(\"https:\")==0 and word.find(\"http:\")==0 and word.find(\"www:\")==0:\n",
    "                continue\n",
    "        elif len(word) > 1 and (word.startswith('#') or word.startswith('@')):\n",
    "            new_sentence = new_sentence + \" \" + word\n",
    "        elif word not in nltk_stop_words:\n",
    "            word = re.sub('[()!?]', '', word)\n",
    "            word = re.sub('\\[.*?\\]','', word)\n",
    "            word = re.sub(\"[^A-Za-z]\",'', word)\n",
    "            base_word = wordnet_lemmatizer.lemmatize(word)\n",
    "            new_sentence = new_sentence + \" \" + base_word \n",
    "    content.append(new_sentence.strip())\n",
    "    label.append(row[1])\n",
    "    #break\n",
    "new_df = pd.DataFrame(\n",
    "    {'content': content,\n",
    "     'label': label\n",
    "    })\n",
    "new_df.sample()\n",
    "#print(f\"{content} and {label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bc20b2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#new_df.to_csv('clean_mendeley_hatespeech_dataset.csv')\n",
    "\n",
    "#new_df[new_df['label'] == 0].to_csv('clean_mendeley_hatespeech_dataset_0.csv')\n",
    "#new_df[new_df['label'] == 1].to_csv('clean_mendeley_hatespeech_dataset_1.csv')\n",
    "for no, chunk in enumerate(np.array_split(new_df, 2)):\n",
    "    suffix = chr(no+65)\n",
    "    chunk.to_csv(f'clean_mendeley_hatespeech_dataset_part{suffix}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ffe034",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
