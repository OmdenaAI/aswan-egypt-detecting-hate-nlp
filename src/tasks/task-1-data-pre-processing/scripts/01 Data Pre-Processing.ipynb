{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d46059cc",
   "metadata": {},
   "source": [
    "# Data Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7731a82",
   "metadata": {},
   "source": [
    "<b>Datasets:</b>\n",
    "\n",
    "Measuring Hate Speech<br>\n",
    "https://huggingface.co/datasets/ucberkeley-dlab/measuring-hate-speech\n",
    "\n",
    "Hate Speech and Offensive Language<br>\n",
    "https://www.kaggle.com/datasets/mrmorj/hate-speech-and-offensive-language-dataset\n",
    "\n",
    "Twitter Sentiment Analysis<br>\n",
    "https://www.kaggle.com/code/imene0swaaaan/twitter-sentiment-analysis/data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29522b26",
   "metadata": {},
   "source": [
    "<b>Measuring Hate Speech</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b856c84",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/datasets/measuring_hate_speech.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/7c/j93bbf715k92mb331s_mlgsc0000gn/T/ipykernel_2788/1312035350.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_option\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'display.max_colwidth'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdf_measuring_hate_speech\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/datasets/measuring_hate_speech.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mdf_measuring_hate_speech\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m9\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    676\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 678\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 575\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    576\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    930\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 932\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    933\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    934\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1214\u001b[0m             \u001b[0;31m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0;31m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1216\u001b[0;31m             self.handles = get_handle(  # type: ignore[call-overload]\n\u001b[0m\u001b[1;32m   1217\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    784\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    785\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 786\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    787\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/datasets/measuring_hate_speech.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "df_measuring_hate_speech = pd.read_csv(\"datasets/measuring_hate_speech.csv\")\n",
    "df_measuring_hate_speech.iloc[:, 9:16].sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4cf7e754",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>corpus_name</th>\n",
       "      <th>raw_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>128863</th>\n",
       "      <td>measuring hate speech</td>\n",
       "      <td>Notwithstanding Marriyum Aurangzeb sahiba's political standing in her own right, amongst the many positives that Maryam Nawaz brought to the Pakistani political arena, bringing our female politicians to the centre-stage is one of the most notable ones. #PakistanStandsWithMaryam URL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130166</th>\n",
       "      <td>measuring hate speech</td>\n",
       "      <td>Notwithstanding Marriyum Aurangzeb sahiba's political standing in her own right, amongst the many positives that Maryam Nawaz brought to the Pakistani political arena, bringing our female politicians to the centre-stage is one of the most notable ones. #PakistanStandsWithMaryam URL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51479</th>\n",
       "      <td>measuring hate speech</td>\n",
       "      <td>Kinda funny how conservative christians fanatically support a pedophile who forcibly raped his second wife and raw dogged pornstars while his 3rd wife was pregnant.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133610</th>\n",
       "      <td>measuring hate speech</td>\n",
       "      <td>Notwithstanding Marriyum Aurangzeb sahiba's political standing in her own right, amongst the many positives that Maryam Nawaz brought to the Pakistani political arena, bringing our female politicians to the centre-stage is one of the most notable ones. #PakistanStandsWithMaryam URL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101528</th>\n",
       "      <td>measuring hate speech</td>\n",
       "      <td>ayo i even kill handicapped and crippled bitches/look at my scalp real close and you'll see triple sixes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  corpus_name  \\\n",
       "128863  measuring hate speech   \n",
       "130166  measuring hate speech   \n",
       "51479   measuring hate speech   \n",
       "133610  measuring hate speech   \n",
       "101528  measuring hate speech   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                      raw_sentence  \n",
       "128863  Notwithstanding Marriyum Aurangzeb sahiba's political standing in her own right, amongst the many positives that Maryam Nawaz brought to the Pakistani political arena, bringing our female politicians to the centre-stage is one of the most notable ones. #PakistanStandsWithMaryam URL  \n",
       "130166  Notwithstanding Marriyum Aurangzeb sahiba's political standing in her own right, amongst the many positives that Maryam Nawaz brought to the Pakistani political arena, bringing our female politicians to the centre-stage is one of the most notable ones. #PakistanStandsWithMaryam URL  \n",
       "51479                                                                                                                         Kinda funny how conservative christians fanatically support a pedophile who forcibly raped his second wife and raw dogged pornstars while his 3rd wife was pregnant.  \n",
       "133610  Notwithstanding Marriyum Aurangzeb sahiba's political standing in her own right, amongst the many positives that Maryam Nawaz brought to the Pakistani political arena, bringing our female politicians to the centre-stage is one of the most notable ones. #PakistanStandsWithMaryam URL  \n",
       "101528                                                                                                                                                                                    ayo i even kill handicapped and crippled bitches/look at my scalp real close and you'll see triple sixes  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_measuring_hate_speech.columns = df_measuring_hate_speech.columns.str.replace('text', 'raw_sentence')\n",
    "df_measuring_hate_speech = df_measuring_hate_speech.assign(corpus_name='measuring hate speech')\n",
    "df_measuring_hate_speech_keep = ['corpus_name','raw_sentence']\n",
    "df_measuring_hate_speech = df_measuring_hate_speech[df_measuring_hate_speech_keep]\n",
    "df_measuring_hate_speech.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb380c9",
   "metadata": {},
   "source": [
    "<b>Hate Speech and Offensive Language</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e43dc6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>count</th>\n",
       "      <th>hate_speech</th>\n",
       "      <th>offensive_language</th>\n",
       "      <th>neither</th>\n",
       "      <th>class</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15629</th>\n",
       "      <td>15995</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>RT @ImNeverChillin: bitches cant finish a 6 inch sub but want a 13 inch dick</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20769</th>\n",
       "      <td>21218</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>She unfollowed me after I said I cried watching dawn of the apes lmaooooooo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15320</th>\n",
       "      <td>15682</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>RT @GabrielaAngela4: @JacklynAnnn I'm not even ghetto!!!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24621</th>\n",
       "      <td>25132</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>u can tell yo bitch we some yung rich homies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13820</th>\n",
       "      <td>14159</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>Photo check for background spooks. http://t.co/Hx1wghJAzy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0  count  hate_speech  offensive_language  neither  class  \\\n",
       "15629       15995      3            0                   3        0      1   \n",
       "20769       21218      3            0                   0        3      2   \n",
       "15320       15682      3            0                   1        2      2   \n",
       "24621       25132      3            0                   3        0      1   \n",
       "13820       14159      3            0                   0        3      2   \n",
       "\n",
       "                                                                              tweet  \n",
       "15629  RT @ImNeverChillin: bitches cant finish a 6 inch sub but want a 13 inch dick  \n",
       "20769   She unfollowed me after I said I cried watching dawn of the apes lmaooooooo  \n",
       "15320                     RT @GabrielaAngela4: @JacklynAnnn I'm not even ghetto!!!!  \n",
       "24621                                  u can tell yo bitch we some yung rich homies  \n",
       "13820                     Photo check for background spooks. http://t.co/Hx1wghJAzy  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_hate_speech_and_offensive_language = pd.read_csv(\"datasets/hate_speech_and_offensive_language.csv\")\n",
    "df_hate_speech_and_offensive_language.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a38ac593",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>corpus_name</th>\n",
       "      <th>raw_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14636</th>\n",
       "      <td>hate speech and offensive language</td>\n",
       "      <td>RT @Cesar_Wtx: Pink nipples are cute but some be looking nasty than a bitch! &amp;#128567;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4838</th>\n",
       "      <td>hate speech and offensive language</td>\n",
       "      <td>@T_FLYE lmaooooo bro you still got that shit you are a hoe we boxing when you come back nigga</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22759</th>\n",
       "      <td>hate speech and offensive language</td>\n",
       "      <td>When you see kids being bad &amp;amp; their parents just standing there &amp;amp; you look @ em like bitch you ain't gon do somethin? http://t.co/1B822azXiQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23349</th>\n",
       "      <td>hate speech and offensive language</td>\n",
       "      <td>You know i stay on fuck a bitch shit but with a street nigga thats what you gonna get .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1696</th>\n",
       "      <td>hate speech and offensive language</td>\n",
       "      <td>&amp;#8220;@anallanusa32: 83 you're really cool you're good at basketball. And your a zebra &amp;#127936;&amp;#128060;&amp;#8221; is this @WillBall4Life?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              corpus_name  \\\n",
       "14636  hate speech and offensive language   \n",
       "4838   hate speech and offensive language   \n",
       "22759  hate speech and offensive language   \n",
       "23349  hate speech and offensive language   \n",
       "1696   hate speech and offensive language   \n",
       "\n",
       "                                                                                                                                               raw_sentence  \n",
       "14636                                                                RT @Cesar_Wtx: Pink nipples are cute but some be looking nasty than a bitch! &#128567;  \n",
       "4838                                                          @T_FLYE lmaooooo bro you still got that shit you are a hoe we boxing when you come back nigga  \n",
       "22759  When you see kids being bad &amp; their parents just standing there &amp; you look @ em like bitch you ain't gon do somethin? http://t.co/1B822azXiQ  \n",
       "23349                                                               You know i stay on fuck a bitch shit but with a street nigga thats what you gonna get .  \n",
       "1696              &#8220;@anallanusa32: 83 you're really cool you're good at basketball. And your a zebra &#127936;&#128060;&#8221; is this @WillBall4Life?  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_hate_speech_and_offensive_language.columns = df_hate_speech_and_offensive_language.columns.str.replace('tweet', 'raw_sentence')\n",
    "df_hate_speech_and_offensive_language = df_hate_speech_and_offensive_language.assign(corpus_name='hate speech and offensive language')\n",
    "df_hate_speech_and_offensive_language_keep = ['corpus_name','raw_sentence']\n",
    "df_hate_speech_and_offensive_language = df_hate_speech_and_offensive_language[df_hate_speech_and_offensive_language_keep]\n",
    "df_hate_speech_and_offensive_language.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6e0a2ce",
   "metadata": {},
   "source": [
    "<b>Twitter Sentiment Analysis</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b18b855",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9039</th>\n",
       "      <td>9040</td>\n",
       "      <td>0</td>\n",
       "      <td>#cat #kitty   select knowledge:</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8379</th>\n",
       "      <td>8380</td>\n",
       "      <td>0</td>\n",
       "      <td>ty 4 ur recent flw @user @user @user   2 connect :) hv a gr8 dy! (want this ð? &amp;gt;&amp;gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11134</th>\n",
       "      <td>11135</td>\n",
       "      <td>0</td>\n",
       "      <td>#euro2016 #marseille how are the security teams supposed to concentrate on keeping crowds safe when they are dealing with drunks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15693</th>\n",
       "      <td>15694</td>\n",
       "      <td>0</td>\n",
       "      <td>we're all heading out 2 #ireland 4 #concepta research. so   2 c #dunaonghasa on #inismor &amp;amp; beautiful #eire!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3100</th>\n",
       "      <td>3101</td>\n",
       "      <td>1</td>\n",
       "      <td>@user \"the holidays are a violent time for me, and iâve begun to question the impoance of families.â#familycircus #chriâ¦</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  label  \\\n",
       "9039    9040      0   \n",
       "8379    8380      0   \n",
       "11134  11135      0   \n",
       "15693  15694      0   \n",
       "3100    3101      1   \n",
       "\n",
       "                                                                                                                                    tweet  \n",
       "9039                                                                                                      #cat #kitty   select knowledge:  \n",
       "8379                                          ty 4 ur recent flw @user @user @user   2 connect :) hv a gr8 dy! (want this ð? &gt;&gt;   \n",
       "11134  #euro2016 #marseille how are the security teams supposed to concentrate on keeping crowds safe when they are dealing with drunks    \n",
       "15693                    we're all heading out 2 #ireland 4 #concepta research. so   2 c #dunaonghasa on #inismor &amp; beautiful #eire!   \n",
       "3100      @user \"the holidays are a violent time for me, and iâve begun to question the impoance of families.â#familycircus #chriâ¦   "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_twitter_sentiment_analysis = pd.read_csv(\"datasets/twitter_sentiment_analysis.csv\")\n",
    "df_twitter_sentiment_analysis.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "03e0f1d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>corpus_name</th>\n",
       "      <th>raw_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14651</th>\n",
       "      <td>twitter sentiment analysis</td>\n",
       "      <td>sterling is making me so angry!   #sterling. ohhh and fuck you @user you nobody!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29583</th>\n",
       "      <td>twitter sentiment analysis</td>\n",
       "      <td>@user matching bags packed ahead of our trip to malaysia! #travels #holidays  !!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11325</th>\n",
       "      <td>twitter sentiment analysis</td>\n",
       "      <td>@user @user i feel personally victimized by the fact that you aren't coming to acu on this tour. #ouch #heabroken #huâ¦</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6109</th>\n",
       "      <td>twitter sentiment analysis</td>\n",
       "      <td>@user yepp #depression #anxiety #anorexia   #quotes #secret_society123 #grunge #girl #suicide #l4l #smile escapinqlifee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22739</th>\n",
       "      <td>twitter sentiment analysis</td>\n",
       "      <td>1 week until we leave for hellfest!! i can't wait. i need a holiday   #holiday #festivals</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      corpus_name  \\\n",
       "14651  twitter sentiment analysis   \n",
       "29583  twitter sentiment analysis   \n",
       "11325  twitter sentiment analysis   \n",
       "6109   twitter sentiment analysis   \n",
       "22739  twitter sentiment analysis   \n",
       "\n",
       "                                                                                                                    raw_sentence  \n",
       "14651                                           sterling is making me so angry!   #sterling. ohhh and fuck you @user you nobody!  \n",
       "29583                                          @user matching bags packed ahead of our trip to malaysia! #travels #holidays  !!   \n",
       "11325   @user @user i feel personally victimized by the fact that you aren't coming to acu on this tour. #ouch #heabroken #huâ¦  \n",
       "6109    @user yepp #depression #anxiety #anorexia   #quotes #secret_society123 #grunge #girl #suicide #l4l #smile escapinqlifee   \n",
       "22739                                1 week until we leave for hellfest!! i can't wait. i need a holiday   #holiday #festivals    "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_twitter_sentiment_analysis.columns = df_twitter_sentiment_analysis.columns.str.replace('tweet', 'raw_sentence')\n",
    "df_twitter_sentiment_analysis = df_twitter_sentiment_analysis.assign(corpus_name='twitter sentiment analysis')\n",
    "df_twitter_sentiment_analysis_keep = ['corpus_name','raw_sentence']\n",
    "df_twitter_sentiment_analysis = df_twitter_sentiment_analysis[df_twitter_sentiment_analysis_keep]\n",
    "df_twitter_sentiment_analysis.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e00c28d5",
   "metadata": {},
   "source": [
    "<b>Combine 3 dataset</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "12c1be76",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7c/j93bbf715k92mb331s_mlgsc0000gn/T/ipykernel_37168/2318947973.py:1: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_combine = df_measuring_hate_speech.append(df_hate_speech_and_offensive_language)\n"
     ]
    }
   ],
   "source": [
    "df_combine = df_measuring_hate_speech.append(df_hate_speech_and_offensive_language)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "12b50d4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7c/j93bbf715k92mb331s_mlgsc0000gn/T/ipykernel_37168/3029402190.py:1: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df_combine.append(df_twitter_sentiment_analysis)\n"
     ]
    }
   ],
   "source": [
    "df = df_combine.append(df_twitter_sentiment_analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "20ff00f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>corpus_name</th>\n",
       "      <th>raw_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3371</th>\n",
       "      <td>measuring hate speech</td>\n",
       "      <td>Reddit doesn't care if they aren't white.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76636</th>\n",
       "      <td>measuring hate speech</td>\n",
       "      <td>*Le Commie retard woman: Sanghi men UgLy. No girl marry Sanghi man. Sanghi man boooooo! Meanwhile commies be looking like this 🤣 URL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104645</th>\n",
       "      <td>measuring hate speech</td>\n",
       "      <td>Every slant in #LosAngeles should be deported. Those scum have no right to be here. Chinatown should be bulldozed.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131272</th>\n",
       "      <td>measuring hate speech</td>\n",
       "      <td>I love that you enjoy being trans.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62714</th>\n",
       "      <td>measuring hate speech</td>\n",
       "      <td>It's always the jews.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  corpus_name  \\\n",
       "3371    measuring hate speech   \n",
       "76636   measuring hate speech   \n",
       "104645  measuring hate speech   \n",
       "131272  measuring hate speech   \n",
       "62714   measuring hate speech   \n",
       "\n",
       "                                                                                                                                raw_sentence  \n",
       "3371                                                                                               Reddit doesn't care if they aren't white.  \n",
       "76636   *Le Commie retard woman: Sanghi men UgLy. No girl marry Sanghi man. Sanghi man boooooo! Meanwhile commies be looking like this 🤣 URL  \n",
       "104645                    Every slant in #LosAngeles should be deported. Those scum have no right to be here. Chinatown should be bulldozed.  \n",
       "131272                                                                                                    I love that you enjoy being trans.  \n",
       "62714                                                                                                                  It's always the jews.  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a6684691",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(192301, 2)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25e5475f",
   "metadata": {},
   "source": [
    "<b>Text Clean Process</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7a2ab498",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/christianmdelossantos/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/christianmdelossantos/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/christianmdelossantos/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"wordnet\")\n",
    "\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def clean_text(text):\n",
    "    \n",
    "    tokens = re.sub(r'http\\S+', '', text, flags=re.MULTILINE)\n",
    "    tokens = re.sub('<[^<]+?>', '', tokens)\n",
    "    tokens = re.sub('@\\w+', '', tokens)\n",
    "    tokens = re.sub('^RT\\s', '', tokens)\n",
    "    \n",
    "    tokens = word_tokenize(tokens)\n",
    "    \n",
    "    tokens = [token for token in tokens if token not in stop_words and token.isalpha()]\n",
    "    tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "    \n",
    "    cleaned_text = \" \".join(tokens)\n",
    "    \n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "492efff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"clean_sentence_training\"] = df[\"raw_sentence\"].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4512f301",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "# remove all words less than and equal 3 letters\n",
    "df['third_clean'] = df['clean_sentence_training'].apply(lambda x: ' '.join([w for w in x.split() if len(w)>3]))\n",
    "\n",
    "# remove all duplicate word\n",
    "df['fourth_clean'] = (df['third_clean'].str.split().apply(lambda x: OrderedDict.fromkeys(x).keys()).str.join(' '))\n",
    "\n",
    "df['clean_sentence_training'] = df['fourth_clean']\n",
    "\n",
    "df = df.drop(['third_clean','fourth_clean'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ff6318c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>corpus_name</th>\n",
       "      <th>raw_sentence</th>\n",
       "      <th>clean_sentence_training</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29702</th>\n",
       "      <td>measuring hate speech</td>\n",
       "      <td>@RaheelChauhdary @zainabzara77 @Ashutos85588843 @ZaidZamanHamid I didn't ask because I found out on my own. O/w it is gud if parents mak children understand of bodily process and safety precautions&amp;morality in safe environment URL preachers can talk of unbending penis but beneficiary of d scheme(girl) is not 2b informed?😂</td>\n",
       "      <td>found parent child understand bodily process safety precaution morality safe environment preacher talk unbending penis beneficiary scheme girl informed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7879</th>\n",
       "      <td>hate speech and offensive language</td>\n",
       "      <td>Ayyyyy I'm sipping on a free slurpee and seeing The Front Bottoms tonight. I'm a happy clam.</td>\n",
       "      <td>Ayyyyy sipping free slurpee seeing Front Bottoms tonight happy clam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72944</th>\n",
       "      <td>measuring hate speech</td>\n",
       "      <td>She's a useless cunt.</td>\n",
       "      <td>useless cunt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4502</th>\n",
       "      <td>hate speech and offensive language</td>\n",
       "      <td>@RealSkipBayless @KingJames is a little bitch , that's why</td>\n",
       "      <td>little bitch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84082</th>\n",
       "      <td>measuring hate speech</td>\n",
       "      <td>Let's break it on down. Rails against mentally ill youth likely caused by whatever lack of personal accountability. jpeg and fame whore culture while also being a mentally ill fame whore. K.</td>\n",
       "      <td>break Rails mentally youth likely caused whatever lack personal accountability jpeg fame whore culture also</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24289</th>\n",
       "      <td>measuring hate speech</td>\n",
       "      <td>I would like to see the scam forcing all the elites presidents movie stars models elite families to be transgendered for God knows how long thinking this is what they had to do to keep their wealth and power. All these people are set free of this scam and bond as well. They are all soul healed.</td>\n",
       "      <td>would like scam forcing elite president movie star model family transgendered know long thinking keep wealth power people free bond well They soul healed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10454</th>\n",
       "      <td>twitter sentiment analysis</td>\n",
       "      <td>â #fomc committee to maintain the fed funds target range unchanged â danske bank   #blog #silver #gold #forex</td>\n",
       "      <td>fomc committee maintain fund target range unchanged danske bank blog silver gold forex</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58543</th>\n",
       "      <td>measuring hate speech</td>\n",
       "      <td>It's fine to be upset. Rejection and sexual frustration are upsetting, and you should be allowed to vent your frustrations in a constructive, supportive environment.  It is NOT fine to advocate, threaten, or condone rape. If you think women deserve to be raped because you haven't found someone willing to let you flail pathetically around on them for 43 seconds, then I think you deserve to cry alone, rotting in your semen encrusted underwear alone, until you die. Alone.</td>\n",
       "      <td>fine upset Rejection sexual frustration upsetting allowed vent constructive supportive environment advocate threaten condone rape think woman deserve raped found someone willing flail pathetically around second alone rotting semen encrusted underwear Alone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2400</th>\n",
       "      <td>hate speech and offensive language</td>\n",
       "      <td>@AlexDunlapNFL @BDOE_KLBJ that evil son of a bitch deserves everything that's coming to him</td>\n",
       "      <td>evil bitch deserves everything coming</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28775</th>\n",
       "      <td>twitter sentiment analysis</td>\n",
       "      <td>happy bihday bro @user    #rapmonster</td>\n",
       "      <td>happy bihday rapmonster</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              corpus_name  \\\n",
       "29702               measuring hate speech   \n",
       "7879   hate speech and offensive language   \n",
       "72944               measuring hate speech   \n",
       "4502   hate speech and offensive language   \n",
       "84082               measuring hate speech   \n",
       "24289               measuring hate speech   \n",
       "10454          twitter sentiment analysis   \n",
       "58543               measuring hate speech   \n",
       "2400   hate speech and offensive language   \n",
       "28775          twitter sentiment analysis   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    raw_sentence  \\\n",
       "29702                                                                                                                                                        @RaheelChauhdary @zainabzara77 @Ashutos85588843 @ZaidZamanHamid I didn't ask because I found out on my own. O/w it is gud if parents mak children understand of bodily process and safety precautions&morality in safe environment URL preachers can talk of unbending penis but beneficiary of d scheme(girl) is not 2b informed?😂   \n",
       "7879                                                                                                                                                                                                                                                                                                                                                                                                Ayyyyy I'm sipping on a free slurpee and seeing The Front Bottoms tonight. I'm a happy clam.   \n",
       "72944                                                                                                                                                                                                                                                                                                                                                                                                                                                                      She's a useless cunt.   \n",
       "4502                                                                                                                                                                                                                                                                                                                                                                                                                                  @RealSkipBayless @KingJames is a little bitch , that's why   \n",
       "84082                                                                                                                                                                                                                                                                                             Let's break it on down. Rails against mentally ill youth likely caused by whatever lack of personal accountability. jpeg and fame whore culture while also being a mentally ill fame whore. K.   \n",
       "24289                                                                                                                                                                                    I would like to see the scam forcing all the elites presidents movie stars models elite families to be transgendered for God knows how long thinking this is what they had to do to keep their wealth and power. All these people are set free of this scam and bond as well. They are all soul healed.   \n",
       "10454                                                                                                                                                                                                                                                                                                                                                                          â #fomc committee to maintain the fed funds target range unchanged â danske bank   #blog #silver #gold #forex   \n",
       "58543  It's fine to be upset. Rejection and sexual frustration are upsetting, and you should be allowed to vent your frustrations in a constructive, supportive environment.  It is NOT fine to advocate, threaten, or condone rape. If you think women deserve to be raped because you haven't found someone willing to let you flail pathetically around on them for 43 seconds, then I think you deserve to cry alone, rotting in your semen encrusted underwear alone, until you die. Alone.   \n",
       "2400                                                                                                                                                                                                                                                                                                                                                                                                 @AlexDunlapNFL @BDOE_KLBJ that evil son of a bitch deserves everything that's coming to him   \n",
       "28775                                                                                                                                                                                                                                                                                                                                                                                                                                                     happy bihday bro @user    #rapmonster    \n",
       "\n",
       "                                                                                                                                                                                                                                                clean_sentence_training  \n",
       "29702                                                                                                           found parent child understand bodily process safety precaution morality safe environment preacher talk unbending penis beneficiary scheme girl informed  \n",
       "7879                                                                                                                                                                                                Ayyyyy sipping free slurpee seeing Front Bottoms tonight happy clam  \n",
       "72944                                                                                                                                                                                                                                                      useless cunt  \n",
       "4502                                                                                                                                                                                                                                                       little bitch  \n",
       "84082                                                                                                                                                       break Rails mentally youth likely caused whatever lack personal accountability jpeg fame whore culture also  \n",
       "24289                                                                                                         would like scam forcing elite president movie star model family transgendered know long thinking keep wealth power people free bond well They soul healed  \n",
       "10454                                                                                                                                                                            fomc committee maintain fund target range unchanged danske bank blog silver gold forex  \n",
       "58543  fine upset Rejection sexual frustration upsetting allowed vent constructive supportive environment advocate threaten condone rape think woman deserve raped found someone willing flail pathetically around second alone rotting semen encrusted underwear Alone  \n",
       "2400                                                                                                                                                                                                                              evil bitch deserves everything coming  \n",
       "28775                                                                                                                                                                                                                                           happy bihday rapmonster  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "001f2385",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>corpus_name</th>\n",
       "      <th>raw_sentence</th>\n",
       "      <th>clean_sentence_training</th>\n",
       "      <th>textblob_polarity</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2447</th>\n",
       "      <td>twitter sentiment analysis</td>\n",
       "      <td>dese niggas will show dese otha bitches on fb, snap nd twitter more attention then dey do their own girl   but #true ð¯</td>\n",
       "      <td>dese nigga show otha bitch snap twitter attention girl true</td>\n",
       "      <td>0.35</td>\n",
       "      <td>non-risky</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3215</th>\n",
       "      <td>twitter sentiment analysis</td>\n",
       "      <td>@user #prayfororlando we as a nation would hope our intelligence agencies would have... more intelligence, apparently not so.</td>\n",
       "      <td>prayfororlando nation would hope intelligence agency apparently</td>\n",
       "      <td>0.05</td>\n",
       "      <td>non-risky</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50186</th>\n",
       "      <td>measuring hate speech</td>\n",
       "      <td>Your an illegal alien with no respect for the U.S. calling us lazy. You need to be deported with no chance of ever becoming an American citizen. Let me look up I.C.E.s phone number. I'll have them drop by.</td>\n",
       "      <td>Your illegal alien respect calling lazy need deported chance ever becoming American citizen look phone number drop</td>\n",
       "      <td>-0.11</td>\n",
       "      <td>potentially-risky</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58614</th>\n",
       "      <td>measuring hate speech</td>\n",
       "      <td>@BouffantBlessed @Andrewduncun1 maybe we should ask why douche bag men like you look at women as sex objects, instead you should revere us because without us douche bags like you would have been wasted in the toilet by ur daddy.</td>\n",
       "      <td>maybe douche like look woman object instead revere without would wasted toilet daddy</td>\n",
       "      <td>-0.12</td>\n",
       "      <td>potentially-risky</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24526</th>\n",
       "      <td>hate speech and offensive language</td>\n",
       "      <td>the things I do for this bitch smh</td>\n",
       "      <td>thing bitch</td>\n",
       "      <td>0.00</td>\n",
       "      <td>non-risky</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              corpus_name  \\\n",
       "2447           twitter sentiment analysis   \n",
       "3215           twitter sentiment analysis   \n",
       "50186               measuring hate speech   \n",
       "58614               measuring hate speech   \n",
       "24526  hate speech and offensive language   \n",
       "\n",
       "                                                                                                                                                                                                                               raw_sentence  \\\n",
       "2447                                                                                                              dese niggas will show dese otha bitches on fb, snap nd twitter more attention then dey do their own girl   but #true ð¯   \n",
       "3215                                                                                                        @user #prayfororlando we as a nation would hope our intelligence agencies would have... more intelligence, apparently not so.     \n",
       "50186                         Your an illegal alien with no respect for the U.S. calling us lazy. You need to be deported with no chance of ever becoming an American citizen. Let me look up I.C.E.s phone number. I'll have them drop by.   \n",
       "58614  @BouffantBlessed @Andrewduncun1 maybe we should ask why douche bag men like you look at women as sex objects, instead you should revere us because without us douche bags like you would have been wasted in the toilet by ur daddy.   \n",
       "24526                                                                                                                                                                                                    the things I do for this bitch smh   \n",
       "\n",
       "                                                                                                  clean_sentence_training  \\\n",
       "2447                                                          dese nigga show otha bitch snap twitter attention girl true   \n",
       "3215                                                      prayfororlando nation would hope intelligence agency apparently   \n",
       "50186  Your illegal alien respect calling lazy need deported chance ever becoming American citizen look phone number drop   \n",
       "58614                                maybe douche like look woman object instead revere without would wasted toilet daddy   \n",
       "24526                                                                                                         thing bitch   \n",
       "\n",
       "       textblob_polarity              label  \n",
       "2447                0.35          non-risky  \n",
       "3215                0.05          non-risky  \n",
       "50186              -0.11  potentially-risky  \n",
       "58614              -0.12  potentially-risky  \n",
       "24526               0.00          non-risky  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "def get_pol(texts):\n",
    "    return TextBlob(texts).sentiment.polarity\n",
    "\n",
    "df['textblob_polarity'] = df['clean_sentence_training'].apply(get_pol).round(2)\n",
    "\n",
    "def Analysis(score): \n",
    "    if score >= 0:\n",
    "        return 'non-risky'\n",
    "    \n",
    "    elif score < 0 and score >= -0.5:\n",
    "        return 'potentially-risky'\n",
    "        \n",
    "    elif score <= -0.05:\n",
    "        return 'risky'\n",
    "\n",
    "df[\"label\"] = df[\"textblob_polarity\"].apply(Analysis)\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "750a5532",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['clean_sentence_EDA'] = df['clean_sentence_training']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "62e6559a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('textblob_polarity', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f562282a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>corpus_name</th>\n",
       "      <th>raw_sentence</th>\n",
       "      <th>clean_sentence_training</th>\n",
       "      <th>label</th>\n",
       "      <th>clean_sentence_EDA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>91908</th>\n",
       "      <td>measuring hate speech</td>\n",
       "      <td>what a faggot</td>\n",
       "      <td>faggot</td>\n",
       "      <td>non-risky</td>\n",
       "      <td>faggot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26143</th>\n",
       "      <td>twitter sentiment analysis</td>\n",
       "      <td>people outside of venezuela should do something. we should do something about it!</td>\n",
       "      <td>people outside venezuela something</td>\n",
       "      <td>non-risky</td>\n",
       "      <td>people outside venezuela something</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34085</th>\n",
       "      <td>measuring hate speech</td>\n",
       "      <td>He was also the president that was believed to have said I'll keep those niggers voting Democrat for the next 100 years</td>\n",
       "      <td>also president believed said keep nigger voting Democrat next year</td>\n",
       "      <td>non-risky</td>\n",
       "      <td>also president believed said keep nigger voting Democrat next year</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34398</th>\n",
       "      <td>measuring hate speech</td>\n",
       "      <td>IKR fucking whores deserve to be punished, this is why hell exists for them to burn there</td>\n",
       "      <td>fucking whore deserve punished hell exists burn</td>\n",
       "      <td>risky</td>\n",
       "      <td>fucking whore deserve punished hell exists burn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12690</th>\n",
       "      <td>measuring hate speech</td>\n",
       "      <td>Gross. Crawl back into you tree hollow white woman.</td>\n",
       "      <td>Gross Crawl back tree hollow white woman</td>\n",
       "      <td>potentially-risky</td>\n",
       "      <td>Gross Crawl back tree hollow white woman</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      corpus_name  \\\n",
       "91908       measuring hate speech   \n",
       "26143  twitter sentiment analysis   \n",
       "34085       measuring hate speech   \n",
       "34398       measuring hate speech   \n",
       "12690       measuring hate speech   \n",
       "\n",
       "                                                                                                                  raw_sentence  \\\n",
       "91908                                                                                                            what a faggot   \n",
       "26143                                     people outside of venezuela should do something. we should do something about it!      \n",
       "34085  He was also the president that was believed to have said I'll keep those niggers voting Democrat for the next 100 years   \n",
       "34398                                IKR fucking whores deserve to be punished, this is why hell exists for them to burn there   \n",
       "12690                                                                      Gross. Crawl back into you tree hollow white woman.   \n",
       "\n",
       "                                                  clean_sentence_training  \\\n",
       "91908                                                              faggot   \n",
       "26143                                  people outside venezuela something   \n",
       "34085  also president believed said keep nigger voting Democrat next year   \n",
       "34398                     fucking whore deserve punished hell exists burn   \n",
       "12690                            Gross Crawl back tree hollow white woman   \n",
       "\n",
       "                   label  \\\n",
       "91908          non-risky   \n",
       "26143          non-risky   \n",
       "34085          non-risky   \n",
       "34398              risky   \n",
       "12690  potentially-risky   \n",
       "\n",
       "                                                       clean_sentence_EDA  \n",
       "91908                                                              faggot  \n",
       "26143                                  people outside venezuela something  \n",
       "34085  also president believed said keep nigger voting Democrat next year  \n",
       "34398                     fucking whore deserve punished hell exists burn  \n",
       "12690                            Gross Crawl back tree hollow white woman  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "45cf47bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98423"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ecdd0ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "761ba84c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(93878, 5)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "78cf19b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('data_pre_processing.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
